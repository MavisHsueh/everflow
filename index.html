<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Everriver｜遠傳建設</title>
  <meta name="description" content="Everriver — 水紋過場背景，抽象建築主視覺。" />
  <style>
    html,body { height:100%; margin:0; background:#000; }
    #home { position:relative; width:100vw; height:100vh; color:#fff; overflow:hidden; }
    /* 前景 */
    .fg { position:relative; z-index:20; display:grid; grid-template-columns:1fr 1fr; align-items:center; height:100%;
          padding:0 clamp(16px,6vw,80px); font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,'Noto Sans TC',sans-serif; }
    .right { justify-self:end; text-align:right; }
    .title { display:flex; flex-wrap:wrap; gap:.5ch; justify-content:flex-end; font-weight:300; line-height:1.05;
             font-size:clamp(28px,6vw,64px); margin:0 0 .3em; }
    .subtitle { opacity:.9; font-size:clamp(16px,2.5vw,20px); margin:.5em 0 1em; }
    .btn { display:inline-block; padding:.6em 1.2em; border:1px solid #fff; border-radius:999px; text-decoration:none; color:#fff; font-weight:600; font-size:14px; }
    .btn:hover { background:#fff; color:#96bde1; }
    /* Three.js canvas 容器 */
    #everriver-3d { position:absolute; inset:0; z-index:0; }
    /* 診斷 */
    .diag { position:absolute; right:10px; bottom:10px; z-index:30; background:rgba(0,0,0,.35); color:#fff;
            padding:6px 10px; border-radius:8px; font:12px/1.2 system-ui,Arial; }
  </style>
</head>
<body>
  <!-- 首頁區塊 -->
  <section id="home" class="w-full h-screen bg-black text-white relative overflow-hidden flex items-center justify-center">
    <!-- 背景（Three.js 會在此插入 canvas） -->
    <div id="everriver-3d"></div>

    <!-- 前景內容 -->
    <div class="fg">
      <div></div>
      <div class="right">
        <h1 class="title"><span>Designing</span><span>Future,</span><span>Flowing</span><span>from Today.</span></h1>
        <p class="subtitle">從今天啟流，設計未來</p>
        <a class="btn" href="#about">關於遠傳</a>
      </div>
    </div>

    <div class="diag" id="diag">loading…</div>
  </section>

  <!-- Three.js（CDN，r158） -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.158/build/three.min.js"></script>
  <script>
  (() => {
    const VIDEO_LIST = Array.from({length:6}, (_,i)=>`videos/everflow-background${i+1}.mp4`);
    const SEGMENT_SECONDS = 6.5;
    const TRANSITION_MS   = 900;
    const DISP_MAP_URL    = 'assets/water-displace.png';
    const DISPLACE_STRENGTH = 0.28;

    const host = document.getElementById('everriver-3d');
    const diag = document.getElementById('diag');
    const log  = (s)=>{ if(diag) diag.textContent = s; console.log('[everriver]', s); };

    let renderer;
    try {
      renderer = new THREE.WebGLRenderer({ antialias:true, alpha:true, powerPreference:'high-performance' });
    } catch (e) { log('WebGL init failed'); return; }
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    Object.assign(renderer.domElement.style, { position:'absolute', inset:'0' });
    host.appendChild(renderer.domElement);

    const scene  = new THREE.Scene();
    const camera = new THREE.OrthographicCamera(-1,1,1,-1,0,1);

    // 尺寸
    function resize(){
      const w = host.clientWidth || window.innerWidth;
      const h = host.clientHeight || window.innerHeight;
      renderer.setSize(w,h,false);
      uniforms.screenAspect.value = w/h;
    }
    window.addEventListener('resize', resize);

    // 貼圖
    const loader = new THREE.TextureLoader();
    const dispTex = loader.load(DISP_MAP_URL, ()=>log('displace loaded'), undefined, ()=>log('displace failed'));
    dispTex.wrapS = dispTex.wrapT = THREE.RepeatWrapping;

    // 影片貼圖
    const videos = [makeVideoTexture(), makeVideoTexture()];
    let cur = 0, next = 1, curIndex = 0;

    const uniforms = {
      tFrom: { value: videos[cur].texture },
      tTo:   { value: videos[next].texture },
      tDisp: { value: dispTex },
      progress: { value: 0 },
      strength: { value: DISPLACE_STRENGTH },
      time: { value: 0 },
      texAspectFrom: { value: 16/9 },
      texAspectTo:   { value: 16/9 },
      screenAspect:  { value: 16/9 }
    };

    const material = new THREE.ShaderMaterial({
      uniforms,
      vertexShader: \`
        varying vec2 vUv;
        void main(){ vUv = uv; gl_Position = vec4(position.xy, 0.0, 1.0); }
      \`,
      fragmentShader: \`
        precision highp float;
        uniform sampler2D tFrom,tTo,tDisp;
        uniform float progress,strength,time,texAspectFrom,texAspectTo,screenAspect;
        varying vec2 vUv;

        vec2 coverUv(vec2 uv,float texAspect,float screenAspect){
          float r = screenAspect / texAspect;
          vec2 s = (r>1.0)? vec2(1.0, r): vec2(1.0/r, 1.0);
          return (uv - 0.5) * s + 0.5;
        }
        void main(){
          vec2 uv = vUv;
          vec2 dispUV = vec2(uv.x + time*0.03, uv.y + time*0.02);
          vec2 disp = texture2D(tDisp, dispUV).rg * 2.0 - 1.0;

          float amp = strength * (0.25 + 0.75 * smoothstep(0.0,1.0,progress));
          vec2 uvFrom = coverUv(uv + disp*amp*(1.0 - progress), texAspectFrom, screenAspect);
          vec2 uvTo   = coverUv(uv - disp*amp*(progress),       texAspectTo,   screenAspect);

          vec4 A = texture2D(tFrom, uvFrom);
          vec4 B = texture2D(tTo,   uvTo);

          float edge = smoothstep(progress-0.05, progress+0.05, uv.y);
          gl_FragColor = mix(A,B,edge);
        }
      \`,
      transparent: true
    });

    const quad = new THREE.Mesh(new THREE.PlaneGeometry(2,2), material);
    scene.add(quad);

    // 啟動
    mountVideo(videos[cur],  VIDEO_LIST[curIndex]).then(()=>{
      setAspect(videos[cur], 'from');
      const nextIndex = (curIndex+1)%VIDEO_LIST.length;
      return mountVideo(videos[next], VIDEO_LIST[nextIndex]).then(()=>{
        setAspect(videos[next], 'to');
        uniforms.tFrom.value = videos[cur].texture;
        uniforms.tTo.value   = videos[next].texture;
        resize(); render(); scheduleNext(); log('running');
      });
    }).catch(e=>log('video load failed: '+e));

    const clock = new THREE.Clock();
    function render(){
      uniforms.time.value += clock.getDelta();
      renderer.render(scene, camera);
      requestAnimationFrame(render);
    }

    let timer, busy=false;
    function scheduleNext(){
      clearTimeout(timer);
      timer = setTimeout(()=>goNext(), SEGMENT_SECONDS*1000);
    }
    async function goNext(){
      if (busy) return; busy = true;
      const nextIndex = (curIndex+1)%VIDEO_LIST.length;
      await mountVideo(videos[next], VIDEO_LIST[nextIndex]);
      setAspect(videos[next], 'to');
      uniforms.tFrom.value = videos[cur].texture;
      uniforms.tTo.value   = videos[next].texture;

      const t0 = performance.now();
      (function anim(now){
        const p = Math.min(1, (now - t0)/TRANSITION_MS);
        uniforms.progress.value = p;
        if (p < 1) requestAnimationFrame(anim);
        else finish();
      })(t0);

      function finish(){
        const tmp = cur; cur = next; next = tmp;
        uniforms.tFrom.value = videos[cur].texture;
        uniforms.tTo.value   = videos[next].texture;
        uniforms.progress.value = 0;
        curIndex = nextIndex;
        setAspect(videos[cur], 'from');
        busy=false; scheduleNext();
      }
    }

    function makeVideoTexture(){
      const video = document.createElement('video');
      video.muted = true; video.setAttribute('muted','');
      video.playsInline = true; video.setAttribute('playsinline','');
      video.loop = true; video.crossOrigin = 'anonymous';
      const texture = new THREE.VideoTexture(video);
      texture.minFilter = THREE.LinearFilter;
      texture.magFilter = THREE.LinearFilter;
      texture.generateMipmaps = false;
      return { video, texture };
    }
    function mountVideo(vtex, src){
      return new Promise((resolve,reject)=>{
        vtex.video.oncanplay = null; vtex.video.onerror = null;
        vtex.video.src = src;
        vtex.video.oncanplay = () => { vtex.video.play().then(resolve).catch(resolve); };
        vtex.video.onerror = () => reject(src);
        vtex.video.load();
      });
    }
    function setAspect(vtex, which){
      const vw = vtex.video.videoWidth  || 1920;
      const vh = vtex.video.videoHeight || 1080;
      const a  = vw / vh;
      if (which==='from') uniforms.texAspectFrom.value = a;
      else uniforms.texAspectTo.value = a;
    }
  })();
  </script>
</body>
</html>
